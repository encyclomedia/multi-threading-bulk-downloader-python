{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29579fa0",
   "metadata": {},
   "source": [
    "<h1>Web-Scraper and Bulk-Downloader with Python using <br>BeautifulSoup and multiprocessing ThreadPool class.</h1>\n",
    "\n",
    "<p>In this Notebook I will be presenting a web-scraper and bulk-downloader with Python, which enables us to download several files from a given url using Python's 3rd Party WebScraper Module `BeautifulSoup` and  the multiprocessing class `ThreadPool`. The goal is to demonstrate the benefit of the multithreading in comparison to popular loops by executing repeated tasks in a shorter time - in this case downloading of csv files.</p>\n",
    "\n",
    "<p>Farshad Davoodifard<br>Berlin, November 2021<br><i>Level: beginner</i></p>\n",
    "\n",
    "<h3>Content</h3>\n",
    "<ol>\n",
    "    <li><a href=\"#1\">Introduction</a></li>\n",
    "    <li><a href=\"#2\">Data</a></li>\n",
    "    <li><a href=\"#3\">Exploratory Data Analysis and Preparation</a></li>\n",
    "    <li><a href=\"#4\">Extracting and Preparing Download Links</a></li>\n",
    "    <li><a href=\"#5\">Download the Target Files</a></li>\n",
    "    <li><a href=\"#6\">Checking the Results and some Notes</a></li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2a737",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "    <h3>1. Introduction</h3>\n",
    "    <p>Upon searching for some appropriate public datasets for machine learning exercises (as alternate for the usual built-in datasets in popular machine learning libraries like the well-known 'iris' dataset in scikit-learn), my attention was brought to a very interesting github repository having a collection of over 1300 datasets originally distributed in R packages, which could be interesting for ML exerciese with Python, too.</p>\n",
    "    <p>Despite the fact that Pandas library is able to read any csv's content from a url, I was rather interested in 'Downloading' the whole data from this repository, before accessing any of them individually - just for fun.</p>\n",
    "    <p>So I decided to develop a Web-Scraper to analyse the content of the above mentioned repository and then tried to download the files automatically using their given links.</p>\n",
    "    <p>In the following lines, I will present all the steps I did to reach my goal.</p>\n",
    "    <p>Have fun and feel free to use my code and share it.</p>\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0970d",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "    <h3>2. Data</h3>\n",
    "    <p>As mentioned in the Introduction, for the data source I am using the public repository of Vincent Arel-Bundock's Project Datasets, which are publically accessible <a href='https://vincentarelbundock.github.io/Rdatasets/datasets.html'>here</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c2ef4",
   "metadata": {},
   "source": [
    "<div id=\"3\">\n",
    "    <h3>3. Exploratory Data Analysis and Preparation</h3>\n",
    "    <p>First of all we need to import all libraries we need for this project. Please consider installing 3rd Party Modules like BeautifulSoup and ThreadPool before you start, as these are not part of Python's standard library.</p>\n",
    "    <p>For more Information on these libraries see their respective documentations.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974bd7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries  imported Successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import httplib2\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.pool import ThreadPool\n",
    "print('Libraries  imported Successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e433171",
   "metadata": {},
   "source": [
    "Now we are going to have a look at the content of our data source. We just save it in a variable called `url`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227c801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL saved!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://vincentarelbundock.github.io/Rdatasets/datasets.html'\n",
    "print('URL saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dc4c1",
   "metadata": {},
   "source": [
    "In the next step we read the page content and display it as a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fad0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe out of html table \n",
    "df = pd.read_html(url)[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca7e789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Item</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Cols</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>n_character</th>\n",
       "      <th>n_factor</th>\n",
       "      <th>n_logical</th>\n",
       "      <th>n_numeric</th>\n",
       "      <th>CSV</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AER</td>\n",
       "      <td>Affairs</td>\n",
       "      <td>Fair's Extramarital Affairs Data</td>\n",
       "      <td>601.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AER</td>\n",
       "      <td>ArgentinaCPI</td>\n",
       "      <td>Consumer Price Index in Argentina</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AER</td>\n",
       "      <td>BankWages</td>\n",
       "      <td>Bank Wages</td>\n",
       "      <td>474.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AER</td>\n",
       "      <td>BenderlyZwick</td>\n",
       "      <td>Benderly and Zwick Data: Inflation, Growth and...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AER</td>\n",
       "      <td>BondYield</td>\n",
       "      <td>Bond Yield Data</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Package           Item                                              Title  \\\n",
       "0     AER        Affairs                   Fair's Extramarital Affairs Data   \n",
       "1     AER   ArgentinaCPI                  Consumer Price Index in Argentina   \n",
       "2     AER      BankWages                                         Bank Wages   \n",
       "3     AER  BenderlyZwick  Benderly and Zwick Data: Inflation, Growth and...   \n",
       "4     AER      BondYield                                    Bond Yield Data   \n",
       "\n",
       "    Rows  Cols  n_binary  n_character  n_factor  n_logical  n_numeric  CSV  \\\n",
       "0  601.0   9.0       2.0          0.0       2.0        0.0        7.0  CSV   \n",
       "1   80.0   2.0       0.0          0.0       0.0        0.0        2.0  CSV   \n",
       "2  474.0   4.0       2.0          0.0       3.0        0.0        1.0  CSV   \n",
       "3   31.0   5.0       0.0          0.0       0.0        0.0        5.0  CSV   \n",
       "4   60.0   2.0       0.0          0.0       0.0        0.0        2.0  CSV   \n",
       "\n",
       "   Doc  \n",
       "0  DOC  \n",
       "1  DOC  \n",
       "2  DOC  \n",
       "3  DOC  \n",
       "4  DOC  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c85c643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Item</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Cols</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>n_character</th>\n",
       "      <th>n_factor</th>\n",
       "      <th>n_logical</th>\n",
       "      <th>n_numeric</th>\n",
       "      <th>CSV</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>vcd</td>\n",
       "      <td>UKSoccer</td>\n",
       "      <td>UK Soccer Scores</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>vcd</td>\n",
       "      <td>VisualAcuity</td>\n",
       "      <td>Visual Acuity in Left and Right Eyes</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>vcd</td>\n",
       "      <td>VonBort</td>\n",
       "      <td>Von Bortkiewicz Horse Kicks Data</td>\n",
       "      <td>280.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>vcd</td>\n",
       "      <td>WeldonDice</td>\n",
       "      <td>Weldon's Dice Data</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>vcd</td>\n",
       "      <td>WomenQueue</td>\n",
       "      <td>Women in Queues</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Package          Item                                 Title   Rows  Cols  \\\n",
       "1740     vcd      UKSoccer                      UK Soccer Scores   25.0   3.0   \n",
       "1741     vcd  VisualAcuity  Visual Acuity in Left and Right Eyes   32.0   4.0   \n",
       "1742     vcd       VonBort      Von Bortkiewicz Horse Kicks Data  280.0   4.0   \n",
       "1743     vcd    WeldonDice                    Weldon's Dice Data   11.0   2.0   \n",
       "1744     vcd    WomenQueue                       Women in Queues   11.0   2.0   \n",
       "\n",
       "      n_binary  n_character  n_factor  n_logical  n_numeric  CSV  Doc  \n",
       "1740       0.0          0.0       2.0        0.0        1.0  CSV  DOC  \n",
       "1741       1.0          0.0       3.0        0.0        1.0  CSV  DOC  \n",
       "1742       1.0          0.0       2.0        0.0        2.0  CSV  DOC  \n",
       "1743       0.0          0.0       1.0        0.0        1.0  CSV  DOC  \n",
       "1744       0.0          0.0       1.0        0.0        1.0  CSV  DOC  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767247f",
   "metadata": {},
   "source": [
    "We may also have a look at the shape of our dataframe to findout the number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cce7c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1745, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723d97b",
   "metadata": {},
   "source": [
    "and to check more details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6ec152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1745 entries, 0 to 1744\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Package      1745 non-null   object \n",
      " 1   Item         1745 non-null   object \n",
      " 2   Title        1745 non-null   object \n",
      " 3   Rows         1745 non-null   float64\n",
      " 4   Cols         1745 non-null   float64\n",
      " 5   n_binary     1745 non-null   float64\n",
      " 6   n_character  1745 non-null   float64\n",
      " 7   n_factor     1745 non-null   float64\n",
      " 8   n_logical    1745 non-null   float64\n",
      " 9   n_numeric    1745 non-null   float64\n",
      " 10  CSV          1745 non-null   object \n",
      " 11  Doc          1745 non-null   object \n",
      "dtypes: float64(7), object(5)\n",
      "memory usage: 163.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0abb42",
   "metadata": {},
   "source": [
    "From the very first look at the dataframe we can see that there are 1745 rows in the dataframe, which means we can theoretically download 1475 files as `csv` or `doc` files, if all the links work properly and each link refers to a unique dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069c466",
   "metadata": {},
   "source": [
    "The dataframe does not have any column, which shwos the size of each file. Instead, we can see the number of rows and columns in each file. Let's see which file has the largest number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0389fba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414593.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rows = df.Rows.max() # maximum number of Rows\n",
    "max_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5350ce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Item</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Cols</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>n_character</th>\n",
       "      <th>n_factor</th>\n",
       "      <th>n_logical</th>\n",
       "      <th>n_numeric</th>\n",
       "      <th>CSV</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>openintro</td>\n",
       "      <td>military</td>\n",
       "      <td>US Military Demographics</td>\n",
       "      <td>1414593.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Package      Item                     Title       Rows  Cols  \\\n",
       "1180  openintro  military  US Military Demographics  1414593.0   6.0   \n",
       "\n",
       "      n_binary  n_character  n_factor  n_logical  n_numeric  CSV  Doc  \n",
       "1180       2.0          0.0       4.0        1.0        1.0  CSV  DOC  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Rows'] == max_rows] # which sample has the maximum number of Rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648b2e9",
   "metadata": {},
   "source": [
    "As we see, the package `openintro` has 1414593 rows and therefore is the largest package among all 1745 files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd29ec",
   "metadata": {},
   "source": [
    "In a similar way, we may check the packages with the smallest number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252e57a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_rows = df.Rows.min() # minimum number of Rows\n",
    "min_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b56b3c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Item</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Cols</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>n_character</th>\n",
       "      <th>n_factor</th>\n",
       "      <th>n_logical</th>\n",
       "      <th>n_numeric</th>\n",
       "      <th>CSV</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>gap</td>\n",
       "      <td>jma.cojo</td>\n",
       "      <td>Internal functions for gap</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>openintro</td>\n",
       "      <td>fish_oil_18</td>\n",
       "      <td>Findings on n-3 Fatty Acid Supplement Health B...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>reshape2</td>\n",
       "      <td>smiths</td>\n",
       "      <td>Demo data describing the Smiths.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Stat2Data</td>\n",
       "      <td>ChemoTHC</td>\n",
       "      <td>THC for Antinausea Treatment in Chemotherapy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>Stat2Data</td>\n",
       "      <td>Migraines</td>\n",
       "      <td>Migraines and TMS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>Stat2Data</td>\n",
       "      <td>TMS</td>\n",
       "      <td>Migraines and TMS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>tidyr</td>\n",
       "      <td>smiths</td>\n",
       "      <td>Some data about the Smith family</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>DOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Package         Item  \\\n",
       "732         gap     jma.cojo   \n",
       "1127  openintro  fish_oil_18   \n",
       "1332   reshape2       smiths   \n",
       "1420  Stat2Data     ChemoTHC   \n",
       "1516  Stat2Data    Migraines   \n",
       "1581  Stat2Data          TMS   \n",
       "1698      tidyr       smiths   \n",
       "\n",
       "                                                  Title  Rows  Cols  n_binary  \\\n",
       "732                          Internal functions for gap   2.0  16.0      13.0   \n",
       "1127  Findings on n-3 Fatty Acid Supplement Health B...   2.0  48.0      46.0   \n",
       "1332                   Demo data describing the Smiths.   2.0   5.0       2.0   \n",
       "1420       THC for Antinausea Treatment in Chemotherapy   2.0   4.0       4.0   \n",
       "1516                                  Migraines and TMS   2.0   4.0       3.0   \n",
       "1581                                  Migraines and TMS   2.0   4.0       3.0   \n",
       "1698                   Some data about the Smith family   2.0   5.0       2.0   \n",
       "\n",
       "      n_character  n_factor  n_logical  n_numeric  CSV  Doc  \n",
       "732           4.0       0.0        0.0       12.0  CSV  DOC  \n",
       "1127          0.0       0.0        0.0       48.0  CSV  DOC  \n",
       "1332          0.0       1.0        0.0        4.0  CSV  DOC  \n",
       "1420          0.0       1.0        0.0        3.0  CSV  DOC  \n",
       "1516          0.0       1.0        0.0        3.0  CSV  DOC  \n",
       "1581          0.0       1.0        0.0        3.0  CSV  DOC  \n",
       "1698          1.0       0.0        0.0        4.0  CSV  DOC  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Rows'] == min_rows] # which sample(s) have the minimum number of Rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b98e7",
   "metadata": {},
   "source": [
    "We see many files with a small number of (e.g. 1 or 2 ) rows which may be less important and relevant for our machine learning exercises. We let them though be there and will not omit them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a5423",
   "metadata": {},
   "source": [
    "Generating a dataframe out of the html table is nice, but not enough to read the links behind 'CSV' (or 'DOC') to get them download. In addition, we need at least the Titles from the dataframe to name the downloaded files later. To get the links behind the html, we need a web-scraper, which we can develop with BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc52e18",
   "metadata": {},
   "source": [
    "<div id=\"4\">\n",
    "    <h3>4. Extracting and Preparing Download Links</h3>\n",
    "    <p>To begin with, we create an empty list (links) that we will use to store the links that we will extract from the HTML content of the webpage.  \n",
    "Then, we create a <strong>BeautifulSoup()</strong> object and pass the HTML content to it. What it does is it creates a nested representations of the HTML content.  \n",
    "As the final step, what we need to do is actually discover the links from the entire HTML content of the webapage. To do it, we use the <strong>.find_all()</strong> method and let it know that we would like to discover only the tags that are actually links.</p>\n",
    "    <p>\n",
    "        An important note is that <strong>.request()</strong> method returns a tuple with two elements, the first being an instance of a Response class, and the second being the content of the body of the URL we are working with.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb863fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of a class that represents a client HTTP interface\n",
    "http = httplib2.Http()\n",
    "# run http-request\n",
    "response, content = http.request(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50b714f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list (links) \n",
    "# that we will use to store the links that \n",
    "# we will extract from the HTML content of the webpage\n",
    "links=[]\n",
    "\n",
    "# find all 'a' tags (links) in the html-content\n",
    "# and save them in the list of 'links'\n",
    "for link in BeautifulSoup(content).find_all('a', href=True):\n",
    "    links.append(link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f33ab",
   "metadata": {},
   "source": [
    "Now let's check the list of links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1258ed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/doc/AER/Affairs.html',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/ArgentinaCPI.csv',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/doc/AER/ArgentinaCPI.html',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BankWages.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:5] # show the first five elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e93b3d",
   "metadata": {},
   "source": [
    "As we see, there are two links for each file: a link to a csv and a html-link. The number of list elements can prove this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe20eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3490"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23997cb1",
   "metadata": {},
   "source": [
    "Which is exactly the double of the number of rows in our dataframe (i.e 1745).  \n",
    "For our machine learning exercises we will need the csv files only. So let deprecate the html links from our list by slicing over the list with a stepwide of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ed031e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/ArgentinaCPI.csv',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BankWages.csv',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BenderlyZwick.csv',\n",
       " 'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BondYield.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need only csv files\n",
    "csv_links = links[::2]\n",
    "# show the first five elements\n",
    "csv_links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c535edf",
   "metadata": {},
   "source": [
    "As we see, this list has exactly 1745 elements (the same as the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "865322a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c869be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afe188",
   "metadata": {},
   "source": [
    "For the ease of work and a better view, we zip the links and their Items information from our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c76844e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Affairs',\n",
       "  'https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv'),\n",
       " (1,\n",
       "  'ArgentinaCPI',\n",
       "  'https://vincentarelbundock.github.io/Rdatasets/csv/AER/ArgentinaCPI.csv'),\n",
       " (2,\n",
       "  'BankWages',\n",
       "  'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BankWages.csv'),\n",
       " (3,\n",
       "  'BenderlyZwick',\n",
       "  'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BenderlyZwick.csv'),\n",
       " (4,\n",
       "  'BondYield',\n",
       "  'https://vincentarelbundock.github.io/Rdatasets/csv/AER/BondYield.csv')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [(i, df.Item[i], csv_links[i]) for i in range(len(csv_links))]\n",
    "urls[:5]  # show the first five elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b48fef",
   "metadata": {},
   "source": [
    "_**important**_  \n",
    "The latest list will help us to build unique names for the files which are supposed to get downloaded.  \n",
    "We need the digits (say indices) to avoid eliminating/overwriting of files, which may have the same 'name' but different content during the download process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784ae1d",
   "metadata": {},
   "source": [
    "<div id=\"5\">\n",
    "    <h3>5. Download the Target Files</h3>\n",
    " </div>\n",
    " \n",
    "<p>The following function is supposed to download each file individually and save it in the subdirectory 'data'</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85db37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_file(url):\n",
    "    \"\"\"Builds a file name and download and save it to disk.\"\"\"\n",
    "    id_, name, url = url\n",
    "    name = str(id_) + '_'+ name + '.csv'\n",
    "    path = './data/' + name\n",
    "    r = requests.get(url, stream = True)\n",
    "    with open(path, 'wb') as f:\n",
    "         for ch in r:\n",
    "            f.write(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cefb8",
   "metadata": {},
   "source": [
    "To download multiple files at a time, we use the `ThreadPool` method `imap_unordered()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369cf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download using ThreadPool Object with 9 Threads\n",
    "try:\n",
    "    ThreadPool(9).imap_unordered(dl_file, urls)\n",
    "       \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bcfa7c",
   "metadata": {},
   "source": [
    "<div id=\"6\">\n",
    "    <h3>6. Checking the Results and some Notes</h3>\n",
    " </div>\n",
    " \n",
    "<p>To check the number of downloaded files we use the following snippet:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "539278d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('./data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63a3a6",
   "metadata": {},
   "source": [
    "As we see the number of downloaded files is equal to the number of rows in our original dataframe. So we can now reassure that we have downloaded all of the linked files under the `url`. Nevertheles, we cannot be sure that each file is unique regarding its content.  \n",
    "To check this, you may change the structure of the list called `urls` so that every tuple saves without indices - just the Title and the url, and the check the results. Due to some duplicates, you will lose many files because some downloaded files with the same name will overwrite some old ones.  \n",
    "Thank you for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "de"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "de",
   "targetLang": "en",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
